{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f1982d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10369.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU \\\n",
    "    boto3 \\\n",
    "    sagemaker \\\n",
    "    pinecone-client \\\n",
    "    langchain \\\n",
    "    flask \\\n",
    "    \"pandas<2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aceb231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"pineconekey\"\n",
    "BUCKET_NAME=\"assetsbucket\"\n",
    "DOCUMENTATION_FOLDER_NAME=\"sagemaker_documentation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b8ecd15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from typing import List\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class ModelEncoder:\n",
    "    def __init__(self):\n",
    "        self.endpoint_name = \"minilm-embedding\"\n",
    "        self.model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        self.embedding_dimension = 384\n",
    "        self.encoder = Predictor(endpoint_name=self.endpoint_name, serializer=JSONSerializer())\n",
    "    \n",
    "    def embed_docs(self, docs) -> List[List[float]]:\n",
    "        out = self.encoder.predict({\"inputs\": docs})\n",
    "        decoded_string = out.decode('utf-8')\n",
    "        array = json.loads(decoded_string)\n",
    "        embeddings = np.mean(np.array(array), axis=1)\n",
    "        return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce768d42",
   "metadata": {},
   "source": [
    "# Create LLM Generator endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d615d5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "#role_arn = \"arn:aws:iam::${AWS::AccountId}:role/${SageMakerExecutionRole}\"\n",
    "role = sagemaker.get_execution_role()\n",
    "generator_endpoint_name = \"llama-2-generator\"\n",
    "model_id, model_version = \"meta-textgeneration-llama-2-7b-f\", \"2.*\"\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "endpoint_configs = sagemaker_client.list_endpoint_configs()['EndpointConfigs']\n",
    "config_names = [cfg['EndpointConfigName'] for cfg in endpoint_configs]\n",
    "endpoints = sagemaker_client.list_endpoints()['Endpoints']\n",
    "endpoint_names = [ep['EndpointName'] for ep in endpoints]\n",
    "\n",
    "if generator_endpoint_name in config_names and generator_endpoint_name not in endpoint_names:\n",
    "    # Delete config and endpoint and recreate all\n",
    "    sagemaker_client.delete_endpoint_config(EndpointConfigName=generator_endpoint_name)\n",
    "    model = JumpStartModel(model_id=model_id, model_version=model_version)\n",
    "    model.deploy(initial_instance_count=1, instance_type=\"ml.g5.2xlarge\", endpoint_name=generator_endpoint_name)\n",
    "\n",
    "elif generator_endpoint_name not in endpoint_names:\n",
    "    model = JumpStartModel(model_id=model_id, model_version=model_version)\n",
    "    model.deploy(initial_instance_count=1, instance_type=\"ml.g5.2xlarge\", endpoint_name=generator_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6fae8",
   "metadata": {},
   "source": [
    "# Create Embedding Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e065b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "#role_arn = \"arn:aws:iam::${AWS::AccountId}:role/${SageMakerExecutionRole}\"\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "embedding_endpoint_name = \"minilm-embedding\"\n",
    "\n",
    "hub_config = {\n",
    "    \"HF_MODEL_ID\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"HF_TASK\": \"feature-extraction\"\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    env=hub_config,\n",
    "    #role=role_arn,\n",
    "    role=role,\n",
    "    transformers_version= \"4.6\",\n",
    "    pytorch_version = \"1.7\",\n",
    "    py_version = \"py36\"\n",
    ")\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "endpoint_configs = sagemaker_client.list_endpoint_configs()['EndpointConfigs']\n",
    "config_names = [cfg['EndpointConfigName'] for cfg in endpoint_configs]\n",
    "endpoints = sagemaker_client.list_endpoints()['Endpoints']\n",
    "endpoint_names = [ep['EndpointName'] for ep in endpoints]\n",
    "\n",
    "if embedding_endpoint_name in config_names and embedding_endpoint_name not in endpoint_names:\n",
    "    # Delete config and endpoint and recreate all\n",
    "    sagemaker_client.delete_endpoint_config(EndpointConfigName=embedding_endpoint_name)\n",
    "    encoder = huggingface_model.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type=\"ml.m5.large\",\n",
    "            endpoint_name=embedding_endpoint_name\n",
    "        )\n",
    "\n",
    "elif embedding_endpoint_name not in endpoint_names:\n",
    "    encoder = huggingface_model.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type=\"ml.m5.large\",\n",
    "            endpoint_name=embedding_endpoint_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f10e78",
   "metadata": {},
   "source": [
    "# ModelEncoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9ede81a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from typing import List\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class ModelEncoder:\n",
    "    def __init__(self):\n",
    "        self.endpoint_name = \"minilm-embedding\"\n",
    "        self.model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        self.embedding_dimension = 384\n",
    "        self.encoder = Predictor(endpoint_name=self.endpoint_name, serializer=JSONSerializer())\n",
    "    \n",
    "    def embed_docs(self, docs) -> List[List[float]]:\n",
    "        out = self.encoder.predict({\"inputs\": docs})\n",
    "        decoded_string = out.decode('utf-8')\n",
    "        array = json.loads(decoded_string)\n",
    "        embeddings = np.mean(np.array(array), axis=1)\n",
    "        return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf69d6a",
   "metadata": {},
   "source": [
    "# Vector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c577e868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "#from model_enc import ModelEncoder\n",
    "\n",
    "class Vector:\n",
    "    def __init__(self, api_key, environment, index_name):\n",
    "        #os.getenv('PINECONE_API_KEY') \n",
    "        self.api_key = api_key\n",
    "        self.environment = environment # \"gcp-starter\"\n",
    "        self.index_name = index_name #\"rag-aws-poc-index\"\n",
    "        self.k = 4\n",
    "        self.embedding_dimension = 384 #must match ModelEncoder embeding dimension\n",
    "        self.batch_size = 1\n",
    "        self.model_encoder = ModelEncoder()\n",
    "        print(api_key)\n",
    "        pinecone.init(api_key=api_key, environment=environment)\n",
    "        self.index = pinecone.Index(index_name)\n",
    "\n",
    "    \n",
    "    def query(self, query_vec):\n",
    "        top_k_results = self.index.query(query_vec, top_k=self.k, include_metadata=True)\n",
    "        return top_k_results\n",
    "        \n",
    "    def create_vector_store(self):\n",
    "        if self.index_name in pinecone.list_indexes():\n",
    "            pinecone.delete_index(self.index_name)\n",
    "        pinecone.create_index(name=self.index_name, dimension=self.embedding_dimension, metric='cosine')\n",
    "        while not pinecone.describe_index(self.index_name).status['ready']:\n",
    "            time.sleep(1)\n",
    "        return \"Index updated\"\n",
    "    \n",
    "    def embeed_chunks(self, chunks):\n",
    "        for i in tqdm(range(0, len(chunks), self.batch_size)):\n",
    "            i_end = min(i+ self.batch_size, len(chunks))\n",
    "            ids = [str(x) for x in range(i, i_end)]\n",
    "            metas = [{\"text\": text, \"category\": metadata} for text, metadata in zip(chunks['page_content'][i:i_end], chunks['metadata'][i:i_end])]\n",
    "            texts = [text for text in chunks['page_content'][i:i_end].tolist()]\n",
    "            embeddings = self.model_encoder.embed_docs(texts)\n",
    "            records = zip(ids, embeddings, metas)\n",
    "            self.index.upsert(vectors=records)\n",
    "\n",
    "        print(\"Chunks embedded to vector store Succesfully\")    \n",
    "        print(self.index.describe_index_stats())\n",
    "\n",
    "    def chunks_to_vector_store(self, chunks):\n",
    "        self.create_vector_store()\n",
    "        self.embeed_chunks(chunks)\n",
    "        print(\"Index updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c3d51",
   "metadata": {},
   "source": [
    "# ModelGen Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b2ef95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from typing import List\n",
    "from flask import jsonify\n",
    "#from model_enc import ModelEncoder\n",
    "#from vector import Vector\n",
    "import os\n",
    "import json\n",
    "\n",
    "class ModelGenerator:\n",
    "    def __init__(self):\n",
    "        self.endpoint_name = \"llama-2-generator\"\n",
    "        self.predictor = Predictor(endpoint_name=self.endpoint_name, serializer=JSONSerializer())\n",
    "        self.model_encoder = ModelEncoder()\n",
    "        self.vector_store = Vector(\n",
    "            api_key=PINECONE_API_KEY,\n",
    "            environment=\"gcp-starter\",\n",
    "            index_name=\"rag-aws-poc-index\"\n",
    "        )\n",
    "        self.max_section_len = 2000\n",
    "        self.separator = \"\\n\"\n",
    "\n",
    "    def construct_unified_context(self, contexts:List[str]) -> str:\n",
    "        chosen_sections = []\n",
    "        chosen_sections_len = 0\n",
    "        for text in contexts:\n",
    "            text = text.strip()\n",
    "            chosen_sections_len+=len(text)+2\n",
    "            if chosen_sections_len >self.max_section_len:\n",
    "                break\n",
    "            chosen_sections.append(text)\n",
    "        concatenated_doc = self.separator.join(chosen_sections)\n",
    "        print(f\"Chunks used {len(chosen_sections)}, chunks: \\n {concatenated_doc}\")\n",
    "        return concatenated_doc\n",
    "\n",
    "    def create_payload(self, question, context_str) -> dict:\n",
    "        #llama2 compatible prompt\n",
    "        prompt_template = \"\"\"Answer the following QUESTION based on the CONTEXT given. If you do not know the answer and the CONTEXT doesn't\n",
    "        contain the answer truthfully say \"I don't know\".\n",
    "\n",
    "        CONTEXT:\n",
    "        {context}\n",
    "\n",
    "        ANSWER:\n",
    "        \"\"\"\n",
    "        text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
    "        payload = {\n",
    "            \"inputs\":\n",
    "            [\n",
    "                [\n",
    "                {\"role\": \"system\", \"content\": text_input},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "                ]\n",
    "            ],\n",
    "            \"parameters\": {\"max_new_tokens\":256, \"top_p\": 0.9, \"temperature\":0.6, \"return_full_text\":False}\n",
    "        }\n",
    "        return payload\n",
    "    \n",
    "    def predict_with_enriched_context(self, question):\n",
    "        query_vec = self.model_encoder.embed_docs(question)[0]\n",
    "        print(\"queryvec\")\n",
    "        print(query_vec)\n",
    "        top_k_results = self.vector_store.query(query_vec)\n",
    "        print(\"topkresults\")\n",
    "        print(top_k_results)\n",
    "        contexts = [match.metadata[\"text\"] for match in top_k_results.matches]\n",
    "        contexts_str = self.construct_unified_context(contexts)\n",
    "        payload = self.create_payload(question, contexts_str)\n",
    "        out = self.predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "        decoded_string = out.decode('utf-8')\n",
    "        json_response = json.loads(decoded_string)\n",
    "        return json_response[0]['generation']['content'], payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a88879",
   "metadata": {},
   "source": [
    "# Chunk Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b28af4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "class Chunks:\n",
    "    def __init__(self):\n",
    "        self.s3_bucket_name = BUCKET_NAME\n",
    "        self.s3_folder_path = DOCUMENTATION_FOLDER_NAME\n",
    "        self.s3_file_key = 'chunks/pdf_docs_chunks.csv'\n",
    "        self.s3 = boto3.client('s3')\n",
    "        self.chunk_size = 250\n",
    "        self.chunk_overlap = 30\n",
    "\n",
    "    def chunk_markdown_file_by_headers(self, markdown_text):\n",
    "        headers_to_split_on = [\n",
    "            (\"#\", \"Header 1\"),\n",
    "            (\"##\", \"Header 2\"),\n",
    "        ]\n",
    "        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "        md_header_splits = markdown_splitter.split_text(markdown_text)\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap\n",
    "        )\n",
    "        \n",
    "        splits = text_splitter.split_documents(md_header_splits)\n",
    "        return splits\n",
    "\n",
    "    def read_s3_md_files_to_chunks(self, bucket_name, folder_path):\n",
    "        chunks_all_files = []\n",
    "        objects = self.s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_path)\n",
    "\n",
    "        if 'Contents' in objects:\n",
    "            for obj in objects['Contents']:\n",
    "                file_key = obj['Key']\n",
    "                if file_key.endswith('.md'):\n",
    "                    file_obj = self.s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "                    md_content = file_obj['Body'].read().decode('utf-8')\n",
    "                    chunks = self.chunk_markdown_file_by_headers(md_content)\n",
    "                    chunks_all_files.extend(chunks)\n",
    "\n",
    "        return chunks_all_files\n",
    "    \n",
    "    def consolidate_all_chunks_to_csv_and_upload_to_s3(self):\n",
    "        # Read chunks from the specified folder in the S3 bucket\n",
    "        all_chunks = self.read_s3_md_files_to_chunks(self.s3_bucket_name, self.s3_folder_path)\n",
    "        data = [{'page_content': doc.page_content, 'metadata': doc.metadata} for doc in all_chunks]\n",
    "        pdf_docs_chunks = pd.DataFrame(data)\n",
    "        pdf_docs_chunks.to_csv('pdf_docs_chunks.csv', index=False)\n",
    "        self.s3.upload_file('pdf_docs_chunks.csv', self.s3_bucket_name, self.s3_file_key)\n",
    "    \n",
    "    def download_all_csv_chunks_from_s3(self):\n",
    "        file_obj = self.s3.get_object(Bucket=self.s3_bucket_name, Key=self.s3_file_key)\n",
    "        file_content = file_obj['Body'].read().decode('utf-8')\n",
    "        csv_file = StringIO(file_content)\n",
    "        pdf_docs_chunks = pd.read_csv(csv_file)\n",
    "        pdf_docs_chunks.head()\n",
    "        self.s3.download_file(self.s3_bucket_name, self.s3_file_key, 'pdf_docs_chunks.csv')\n",
    "        return pd.read_csv('pdf_docs_chunks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349896e",
   "metadata": {},
   "source": [
    "# Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e99cf60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daa40622-3b52-4ed0-9601-97e2b659dcb1\n",
      "daa40622-3b52-4ed0-9601-97e2b659dcb1\n",
      "queryvec\n",
      "[-0.24050272814929485, -0.34249835337201756, -0.01771362265571952, 0.018120714463293552, -0.1402135300450027, -0.48117613171537715, -0.28832402794311446, -0.008354688373704752, -0.44838136713951826, -0.043116857297718525, -0.10974471007163326, 0.0672216285020113, -0.2832355760037899, 0.12407688323097925, 0.23758704401552677, 0.27310478314757347, -0.13266861718147993, -0.2280914324025313, 0.05726583036206042, -0.10050984813521306, -0.18836369194711247, -0.431924885759751, -0.07180790537192176, 0.35127414266268414, 0.3615265501042207, -0.24020902424429855, -0.1477752561137701, 0.13350998734434447, 0.2778825505326192, 0.027802172194545467, 0.2937460858374834, 0.259618762259682, 0.1474143092830976, 0.16202358823890486, -0.40236254936705035, 0.6843451193223397, -0.3196535559448724, 0.2189745387683312, 0.07986460765823722, 0.1896475109582146, 0.020299059338867664, -0.4585521768312901, -0.01953426011217137, -0.09332909000416596, 0.19167051712671915, -0.17299092126389345, 0.4604939731458823, 0.05287453718483448, -0.017983767747258145, -0.21003859992924845, -0.4314222186803818, -0.5236678123474121, -0.32383287077148754, 0.12686392257455736, -0.4812777216235797, 0.30908717929075163, 0.15328603393087784, -0.3014602670446038, 0.11148768290877342, -0.1685276059433818, 0.33490697853267193, -0.19961267337203026, -0.3153780748446782, -0.09197932419677575, 0.2347237279852076, 0.06374133564531803, -0.27725198958069086, 0.007228997730029126, 0.05071086809039116, -0.6964631055792173, 0.4291781981786092, -0.509268702318271, -0.8354725738366445, 0.33422903530299664, -0.12404920672997832, -0.013148091888676086, -0.23577154520899057, -0.07450087049316305, 0.14552273579950756, -0.24837935878895223, 0.4475126499310136, 0.824549270949016, -0.17337061806271473, 0.15930742248504734, 0.03013657219707966, -0.10411047438780467, 0.38204373481372994, 0.35169553725669783, 0.7530692741274834, -0.46195546568681795, 0.6797476788827529, -0.1559884076899228, -0.6326004092892011, -0.12601323410247764, -0.30846926135321456, 0.03697220240792376, 0.512586041043202, -0.2192280013114214, 0.26197114276389283, 0.32834652190407115, 0.3005673856047603, -0.3595982139231637, 0.09096984976592164, -0.09304339186443637, -0.20732627071750662, 0.4219527766108513, -0.18717698729597032, 0.2973519843071699, 0.10585838711510102, -0.08635307755321264, -0.38624471177657443, 0.08944192947819829, -0.3275552010163665, -0.0915206666298521, -0.1331631246333321, 0.0960511014952014, 0.10492219030857086, 0.20756422262638807, -0.26292435778304935, 0.1757049405326446, 0.03516979399137199, -0.06840558846791585, 0.5316646431941384, 0.22494272670398155, 0.03917909356823657, 0.05750077807654937, -0.14401862708230814, -6.48140065006394e-33, -0.0222782411146909, -0.02286756985510389, -0.08723453991115093, 0.25022771768271923, -0.017292588561152417, 0.22412240644916892, -0.2052396253372232, -0.07538808630003284, -0.03598111883426706, -0.17731857334729284, 0.4056139538685481, 0.1442646085827922, 0.4112318884193276, 0.3615506002485442, 0.420127314204971, -0.3752427709599336, 0.3758923939118783, 0.0972605673596263, 0.2661882263297836, 0.029024739749729633, -0.20139408051424348, -0.06281264048690598, -0.14472909554024227, -0.06035035755485296, 0.27973839656139415, 0.21126604111244282, 0.2899649702012539, 0.34418359662716586, -0.0183340016034587, 0.158708529236416, 0.24184542832275233, -0.19603863079100847, -0.48635660111904144, 0.1168504443873341, 0.3383053032060464, 0.5265617566183209, -0.6334826253975431, -0.9112335021297137, 0.30675538753469783, 0.07561613518434267, -0.2510121500915072, 0.34089905954897404, 0.07697010816385348, 0.311435536093389, -0.08179816789925098, 0.06623143213801086, -0.013512713107047603, 0.18595131735006967, 0.06672515929676592, 0.17055235252094766, -0.7000597330431143, 0.5731174511214098, -0.09563640194634597, 0.054415740499583386, 0.47629732960679877, 0.07095223478972912, 0.1690009975184997, -0.3372592168549697, 0.03649255361718436, -0.06379273921872179, -0.013802257172452906, 0.16288643780474862, -0.5686844860514005, 0.0021938037437697253, -0.01636331497381131, -0.22466976913953354, -0.007303395813020567, 0.602664572497209, 0.31307158368387417, 0.511019729077816, -0.18679443870981535, 0.305178211381038, 0.004404329461976886, 0.3120580685014526, -0.4107821062207222, -0.11100364445398252, -0.27184719262489426, 0.08908733865246177, 0.009454948206742605, 0.09244819233814876, -1.0274402101834614, 0.2935524694621563, 0.005579407016436259, 0.5887207674483458, -0.24900590473165116, -0.0980152504829069, 0.21267334511503577, 0.07848841324448586, -0.22660101655249795, -0.5285939996441206, -0.21545731322839856, 0.559601383904616, -0.2651168309773008, -0.3682033686588208, -0.4392557975758488, 1.6346695357248396e-33, -0.28791822368899983, -0.17791212908923626, -0.12691429955884814, 0.34538758856554824, -0.1233259099535644, -0.3080144568036, -0.06652927617930497, 0.11861881458510955, -0.1188171257575353, 0.10172011078490566, -0.4618030233929555, 0.08372625180830558, 0.2729102975378434, 0.024229039748509724, 0.43185720468560856, 0.11284677655203268, -0.05391566040149579, -0.2939909704340001, -0.3272536489336441, -0.15054665754238764, 0.26627084861199063, 0.09020416252315044, -0.25449952374522883, -0.2923651930953686, -0.14358219224959612, -0.006726531166350469, -0.5431853365153074, -0.5095269797990719, -0.10628801638570924, 0.38956540020687197, 0.2127221136664351, 0.06225981734072169, -0.38777884157995385, -0.06204565579537302, -0.25169247419883806, 0.0835969434119761, 0.14563443108151355, 0.3221771038758258, -0.3037169314920902, 0.18435002533563724, 0.6428101137280464, 0.0995321636243413, 0.5550624886527658, 0.05826553356988976, -0.6211633216589689, 0.14859095805635056, -0.05832585863148173, 0.5651622948547205, -0.05236430404086908, -0.4184297776470582, 0.5119739797276756, 0.13420726622765264, -0.06575246636445324, -0.06000486776853601, -0.013545483195533356, -0.42528936887780827, 0.33131848213573295, 0.14057966127681235, -0.307688116406401, -0.28082557146747905, 0.27703697482744855, 0.2048151489968101, 0.1405357852151307, 0.20579899630198875, -0.12571460008621216, 0.11710854177363217, 0.09548035395952563, 0.3064451143145561, -0.064982404311498, 0.019146844337228686, 0.7225649679700533, -0.0958535946556367, 0.0478156233827273, -0.1930002619434769, -0.22007257615526518, 0.5155504758780202, 0.09315058107798298, 0.015004413784481585, 0.012707834442456564, -0.4533556991567214, 0.6723420632382234, -0.26606732855240506, 0.3937860392034054, -0.11269007126490276, 0.1610653434569637, 0.16256647619108358, -0.5115434130032858, -0.3226107550629725, 0.13009508854399124, -0.014528278261423111, -0.2515548247223099, 0.022265782269338768, -0.4758291505277157, 0.36713309260085225, 0.04970248850683371, -9.634564731205349e-08, -0.2363237775862217, 0.03841110675906142, -0.13276251250257096, 0.1613077058767279, -0.5513854548335075, -0.0018134752754122019, 0.2669731838007768, 0.1136738661137618, -0.17735878502329191, 0.45441698282957077, 0.22572862962260842, -0.14628847956191748, -0.19445228266219297, 0.25215815752744675, 0.2482643609449345, 0.09045628116776545, 0.3933812367419402, 0.5794081265727679, -0.33676945231854916, 0.16707112484922013, 0.09725667722523212, 0.17088584757099548, -0.228775172183911, -0.40272070840001106, 0.012956754847740134, -0.11484051899363597, -0.22179487254470587, 0.4771100471455914, -0.019768354172507923, -0.26153115974739194, 0.5157355135306716, 0.016880117919451248, 0.06193933255660037, 0.14109743565010527, 0.3451582131286462, 0.3617047898781796, -0.8937855896850427, -0.01750127909084161, 0.1101688031728069, -0.11671380139887333, -0.3892995286732912, 0.2979012563203772, 0.0056387462342778845, 0.14500469341874123, 0.19181288049245873, -0.26028421544469893, -0.1430338474456221, -0.15771988111858568, 0.03254087160651883, 0.1450336049310863, -0.21483423359071216, -0.3743923405806224, 0.3789828841884931, 0.026474392972886562, 0.11119016384085019, 0.22591540838281313, 0.0076672194166652234, -0.6357193663716316, -0.2108951210975647, 0.024392676539719105, -0.09751042164862156, -0.3015740054349105, 0.16267200279980898, -0.01567493999997775]\n",
      "topkresults\n",
      "{'matches': [{'id': '6293',\n",
      "              'metadata': {'category': \"{'Header 1': 'SageMaker geospatial \"\n",
      "                                       'capabilities roles<a '\n",
      "                                       'name=\"sagemaker-geospatial-roles\"></a>\\'}',\n",
      "                           'text': 'As a managed service, Amazon SageMaker '\n",
      "                                   'geospatial capabilities perform operations '\n",
      "                                   'on your behalf on the AWS hardware that is '\n",
      "                                   'managed by SageMaker\\\\. It can perform '\n",
      "                                   'only operations that the user permits\\\\.'},\n",
      "              'score': 0.742572486,\n",
      "              'values': []},\n",
      "             {'id': '6295',\n",
      "              'metadata': {'category': \"{'Header 1': 'SageMaker geospatial \"\n",
      "                                       'capabilities roles<a '\n",
      "                                       'name=\"sagemaker-geospatial-roles\"></a>\\', '\n",
      "                                       \"'Header 2': 'Create an execution \"\n",
      "                                       'role<a '\n",
      "                                       'name=\"sagemaker-geospatial-roles-create-execution-role\"></a>\\'}',\n",
      "                           'text': 'To work with SageMaker geospatial '\n",
      "                                   'capabilities you need to setup a user role '\n",
      "                                   'and an execution role\\\\. A user role is an '\n",
      "                                   'AWS identity with permission policies that '\n",
      "                                   'determine what the user can and can not do '\n",
      "                                   'within AWS\\\\. An execution role is an IAM '\n",
      "                                   'role'},\n",
      "              'score': 0.701727867,\n",
      "              'values': []},\n",
      "             {'id': '5118',\n",
      "              'metadata': {'category': \"{'Header 1': 'SageMaker Components for \"\n",
      "                                       'Kubeflow Pipelines<a '\n",
      "                                       'name=\"kubernetes-sagemaker-components-for-kubeflow-pipelines\"></a>\\', '\n",
      "                                       \"'Header 2': 'Kubeflow Pipeline \"\n",
      "                                       'components<a '\n",
      "                                       'name=\"kubeflow-pipeline-components\"></a>\\'}',\n",
      "                           'text': '1. A consistent experience to manage your '\n",
      "                                   'SageMaker resources from any application; '\n",
      "                                   'whether you are using Kubeflow pipelines, '\n",
      "                                   'or Kubernetes CLI \\\\(`kubectl`\\\\) or other '\n",
      "                                   'Kubeflow applications such as '\n",
      "                                   'Notebooks\\\\.'},\n",
      "              'score': 0.635380208,\n",
      "              'values': []},\n",
      "             {'id': '6312',\n",
      "              'metadata': {'category': \"{'Header 1': 'SageMaker geospatial \"\n",
      "                                       'capabilities roles<a '\n",
      "                                       'name=\"sagemaker-geospatial-roles\"></a>\\', '\n",
      "                                       \"'Header 2': 'Passing Roles<a \"\n",
      "                                       'name=\"sagemaker-geospatial-roles-pass-role\"></a>\\'}',\n",
      "                           'text': '[https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html),'},\n",
      "              'score': 0.615787,\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n",
      "Chunks used 4, chunks: \n",
      " As a managed service, Amazon SageMaker geospatial capabilities perform operations on your behalf on the AWS hardware that is managed by SageMaker\\. It can perform only operations that the user permits\\.\n",
      "To work with SageMaker geospatial capabilities you need to setup a user role and an execution role\\. A user role is an AWS identity with permission policies that determine what the user can and can not do within AWS\\. An execution role is an IAM role\n",
      "1. A consistent experience to manage your SageMaker resources from any application; whether you are using Kubeflow pipelines, or Kubernetes CLI \\(`kubectl`\\) or other Kubeflow applications such as Notebooks\\.\n",
      "[https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html),\n",
      " Based on the provided context, SageMaker Geospatial capabilities refer to the ability to perform operations on geospatial data within Amazon Web Services (AWS) using Amazon SageMaker. Specifically, it allows users to perform operations on geospatial data using AWS hardware that is managed by SageMaker, and only permits operations that the user has been granted permission to perform.\n",
      "\n",
      "To use SageMaker Geospatial capabilities, users must set up a user role and an execution role, which are AWS identities with permission policies that determine what the user can and cannot do within AWS. This provides a consistent experience for managing SageMaker resources from any application, including Kubeflow pipelines, the Kubernetes CLI, or other Kubeflow applications such as Notebooks.\n",
      "\n",
      "In summary, SageMaker Geospatial capabilities are a set of features within Amazon SageMaker that enable users to work with geospatial data on AWS, including the ability to perform operations on that data using AWS hardware and permissions managed by SageMaker.\n",
      "payload\n",
      "{'inputs': [[{'role': 'system', 'content': 'Answer the following QUESTION based on the CONTEXT given. If you do not know the answer and the CONTEXT doesn\\'t\\n        contain the answer truthfully say \"I don\\'t know\".\\n\\n        CONTEXT:\\n        As a managed service, Amazon SageMaker geospatial capabilities perform operations on your behalf on the AWS hardware that is managed by SageMaker\\\\. It can perform only operations that the user permits\\\\.\\nTo work with SageMaker geospatial capabilities you need to setup a user role and an execution role\\\\. A user role is an AWS identity with permission policies that determine what the user can and can not do within AWS\\\\. An execution role is an IAM role\\n1. A consistent experience to manage your SageMaker resources from any application; whether you are using Kubeflow pipelines, or Kubernetes CLI \\\\(`kubectl`\\\\) or other Kubeflow applications such as Notebooks\\\\.\\n[https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_geospatial_StartVectorEnrichmentJob.html),\\n\\n        ANSWER:\\n        '}, {'role': 'user', 'content': 'What are SageMaker Geospatial capabilities?'}]], 'parameters': {'max_new_tokens': 256, 'top_p': 0.9, 'temperature': 0.6, 'return_full_text': False}}\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "#from chunks import Chunks\n",
    "#from model_gen import ModelGenerator\n",
    "#from vector import Vector\n",
    "import os\n",
    "#app = Flask(__name__)\n",
    "\n",
    "model_gen = ModelGenerator()\n",
    "chunk_manager = Chunks()\n",
    "\n",
    "vector_store = Vector(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=\"gcp-starter\",\n",
    "    index_name=\"rag-aws-poc-index\"\n",
    ")\n",
    "#data = request.get_json(force=True)\n",
    "question = \"What are SageMaker Geospatial capabilities?\"\n",
    "#if not question:\n",
    "#    return jsonify({\"error\": \"No question provided\"})\n",
    "out, payload = model_gen.predict_with_enriched_context(question)\n",
    "print(out)\n",
    "print(\"payload\")\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3de6e6-f66f-4517-9c48-9eab97adea32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1e9b3-8677-4dd9-81de-58ad8aad583d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
